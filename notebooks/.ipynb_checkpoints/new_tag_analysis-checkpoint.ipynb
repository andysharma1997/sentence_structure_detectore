{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import spacy\n",
    "import seaborn as sns\n",
    "import os\n",
    "sns.set()\n",
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(os.path.join(os.path.abspath(\"../notebooks/data\"),\"razor_lq_data_tags.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 1'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"Unnamed: 0\":\"sentences\",\"Unnamed: 1\":'tags'},inplace=True)\n",
    "df.fillna(\"0\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which class does your child study in?</td>\n",
       "      <td>&lt;w question&gt;&lt;ccontextnoun&gt;&lt;do&gt;&lt;possessive&gt;&lt;per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>which standard is he in?</td>\n",
       "      <td>&lt;wquestion&gt;&lt;contextnoun&gt;&lt;do&gt;&lt;pronoun&gt;&lt;preposit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How many marks did he get in his exams?</td>\n",
       "      <td>&lt;question&gt;&lt;pronoun&gt;&lt;contextnoun&gt;&lt;do&gt;&lt;pronoun&gt;&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How did he grade in the exams?</td>\n",
       "      <td>&lt;question&gt;&lt;do&gt;&lt;pronoun&gt;&lt;verb&gt;&lt;preposition&gt;&lt;adj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How many marks did he get in the assessments?</td>\n",
       "      <td>&lt;question&gt;&lt;adjective&gt;&lt;contextnoun&gt;&lt;do&gt;&lt;pronoun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       sentences  \\\n",
       "0          Which class does your child study in?   \n",
       "1                       which standard is he in?   \n",
       "2        How many marks did he get in his exams?   \n",
       "3                 How did he grade in the exams?   \n",
       "4  How many marks did he get in the assessments?   \n",
       "\n",
       "                                                tags  \n",
       "0  <w question><ccontextnoun><do><possessive><per...  \n",
       "1  <wquestion><contextnoun><do><pronoun><preposit...  \n",
       "2  <question><pronoun><contextnoun><do><pronoun><...  \n",
       "3  <question><do><pronoun><verb><preposition><adj...  \n",
       "4  <question><adjective><contextnoun><do><pronoun...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The List of valid Tags.\n",
    "real_tags = [\n",
    " 'adjective',\n",
    " 'adverb',\n",
    " 'article',\n",
    " 'conjunction',\n",
    " 'contextnoun',\n",
    " 'determiner',\n",
    " 'do',\n",
    " 'domainnoun',\n",
    " 'noun',\n",
    " 'personentitynouns',\n",
    " 'possessive',\n",
    " 'preposition',\n",
    " 'pronoun',\n",
    " 'tense',\n",
    " 'verb',\n",
    " 'wquestion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance as levenshtein_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 0 rows\n",
      "done 1 rows\n",
      "done 2 rows\n",
      "done 3 rows\n",
      "done 4 rows\n",
      "done 5 rows\n",
      "done 6 rows\n",
      "done 7 rows\n",
      "done 8 rows\n",
      "done 9 rows\n",
      "done 10 rows\n",
      "done 11 rows\n",
      "done 12 rows\n",
      "done 13 rows\n",
      "done 14 rows\n",
      "done 15 rows\n",
      "done 16 rows\n",
      "done 17 rows\n",
      "done 18 rows\n",
      "done 19 rows\n",
      "done 20 rows\n",
      "done 21 rows\n",
      "done 22 rows\n",
      "done 23 rows\n",
      "done 24 rows\n",
      "done 25 rows\n",
      "done 26 rows\n",
      "done 27 rows\n",
      "done 28 rows\n",
      "done 29 rows\n",
      "done 30 rows\n",
      "done 31 rows\n",
      "done 32 rows\n",
      "done 33 rows\n",
      "done 34 rows\n",
      "done 35 rows\n",
      "done 36 rows\n",
      "done 37 rows\n",
      "done 38 rows\n",
      "done 39 rows\n",
      "done 40 rows\n",
      "done 41 rows\n",
      "done 42 rows\n",
      "done 43 rows\n",
      "done 44 rows\n",
      "done 45 rows\n",
      "done 46 rows\n",
      "done 47 rows\n",
      "done 48 rows\n",
      "done 49 rows\n",
      "done 50 rows\n",
      "done 51 rows\n",
      "done 52 rows\n",
      "done 53 rows\n",
      "done 54 rows\n",
      "done 55 rows\n",
      "done 56 rows\n",
      "done 57 rows\n",
      "done 58 rows\n",
      "skipping 59 row\n",
      "done 60 rows\n",
      "done 61 rows\n",
      "done 62 rows\n",
      "done 63 rows\n",
      "done 64 rows\n",
      "done 65 rows\n",
      "done 66 rows\n",
      "done 67 rows\n",
      "done 68 rows\n",
      "done 69 rows\n",
      "done 70 rows\n",
      "done 71 rows\n",
      "done 72 rows\n",
      "done 73 rows\n",
      "done 74 rows\n",
      "done 75 rows\n",
      "done 76 rows\n",
      "done 77 rows\n",
      "done 78 rows\n",
      "done 79 rows\n",
      "done 80 rows\n",
      "done 81 rows\n",
      "done 82 rows\n",
      "done 83 rows\n",
      "done 84 rows\n",
      "done 85 rows\n",
      "done 86 rows\n",
      "done 87 rows\n",
      "done 88 rows\n",
      "done 89 rows\n",
      "done 90 rows\n",
      "done 91 rows\n",
      "done 92 rows\n",
      "done 93 rows\n",
      "done 94 rows\n",
      "done 95 rows\n",
      "done 96 rows\n",
      "done 97 rows\n",
      "done 98 rows\n",
      "done 99 rows\n",
      "done 100 rows\n",
      "done 101 rows\n",
      "done 102 rows\n",
      "done 103 rows\n",
      "done 104 rows\n",
      "done 105 rows\n",
      "done 106 rows\n",
      "done 107 rows\n",
      "done 108 rows\n",
      "done 109 rows\n",
      "done 110 rows\n"
     ]
    }
   ],
   "source": [
    "with open(\"/path/to/file/test_3.txt\",'a') as fp:\n",
    "    for i,val in df.iterrows():\n",
    "        if val[1] !='0':\n",
    "            doc = nlp(val[0])\n",
    "            token_string=''\n",
    "            pos_sting = ''\n",
    "            tag_string=''\n",
    "            spacy_tag = ''\n",
    "            for tok in doc:\n",
    "                token_string+=''.join(str(tok))+\"  |  \"\n",
    "                pos_sting+=''.join(str(tok.pos_))+\"  |  \"\n",
    "                spacy_tag+=''.join(str(tok.tag_))+\"  |  \"\n",
    "            tags = val[1].split(\"><\")\n",
    "            tags[0]=tags[0][1:]\n",
    "            tags[-1]=tags[-1][:-1]\n",
    "            for tag in tags:\n",
    "                max_distance = 100\n",
    "                for real_tag in real_tags:\n",
    "                    distance = levenshtein_distance(real_tag,tag)\n",
    "                    if distance < max_distance:\n",
    "                        max_distance = distance\n",
    "                        cleaned_tag = real_tag                \n",
    "                  tag_string+=''.join(cleaned_tag)+\"  |  \"\n",
    "\n",
    "            fp.write(\"\\n\")\n",
    "            fp.write(token_string[:-1])\n",
    "            fp.write(\"\\n\")\n",
    "            fp.write(tag_string[:-1])\n",
    "            fp.write(\"\\n\")\n",
    "            fp.write(spacy_tag[:-1])\n",
    "            fp.write(\"\\n\")\n",
    "            fp.write(pos_sting[:-1])\n",
    "            fp.write(\"\\n\")\n",
    "            fp.write(\"\\n\")\n",
    "            fp.write(\"\\n\")\n",
    "            print(\"done {} rows\".format(i))\n",
    "        else:\n",
    "            print(\"skipping {} row\".format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "counting the no_of tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_set=set()\n",
    "for i,val in df.iterrows():\n",
    "    if val[1]!='0':\n",
    "        tags = val[1].split(\"><\")\n",
    "        tags[0]=tags[0][1:]\n",
    "        tags[-1]=tags[-1][:-1]\n",
    "        for item in tags:\n",
    "            tag_set.add(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adejective',\n",
       " 'adjective',\n",
       " 'adverb',\n",
       " 'article',\n",
       " 'aticle',\n",
       " 'ccontextnoun',\n",
       " 'conjunction',\n",
       " 'contentextnoun',\n",
       " 'context noun',\n",
       " 'contextnoun',\n",
       " 'contextnun',\n",
       " 'determiner',\n",
       " 'do',\n",
       " 'domainnoun',\n",
       " 'noun',\n",
       " 'personentitynouns',\n",
       " 'possessive',\n",
       " 'preposition',\n",
       " 'prepositions',\n",
       " 'prepositon',\n",
       " 'prepostion',\n",
       " 'pronoun',\n",
       " 'pronun',\n",
       " 'prounoun',\n",
       " 'question',\n",
       " 'tense',\n",
       " 'verb',\n",
       " 'verv',\n",
       " 'w question',\n",
       " 'whquestion',\n",
       " 'wquestion'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj=['adejective','adjective']\n",
    "adverb=[\"adverb\"]\n",
    "article=['article',\"aticle\"]\n",
    "contextnoun=['ccontextnoun','contentextnoun','context noun','contextnoun','contextnun','personentitynouns']\n",
    "conjunction = ['conjunction']\n",
    "determiner = [\"determiner\"]\n",
    "auxilary = [\"do\"]\n",
    "domain_noun=['domainnoun']\n",
    "noun = [\"noun\"]\n",
    "pronoun=[\"possessive\",\"pronoun\",\"pronun\",\"prounoun\"]\n",
    "preposition=[\"preposition\",\"prepositions\",\"prepositon\",\"prepostion\"]\n",
    "wquestion=[\"question\",\"w question\",\"whquestion\",\"wquestion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =[]\n",
    "for i,val in df.iterrows():\n",
    "    if val[1]!='0':\n",
    "        sent = val[0]\n",
    "        tok = sent.split()\n",
    "        if tok[-1][-1] == \"?\":\n",
    "            tok[-1]=tok[-1][:-1]\n",
    "        tags = val[1].split(\"><\")\n",
    "        tags[0]=tags[0][1:]\n",
    "        tags[-1]=tags[-1][:-1]\n",
    "        data.append({\"sentence\":sent,\"tokens\":tok,\"tags\":tags})\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tags={\"adj\":['adejective','adjective'],\"adverb\"=[\"adverb\"],\"article\":['article',\"aticle\"],\"contextnoun\":['ccontextnoun','contentextnoun','context noun','contextnoun','contextnun','personentitynouns'],\"conjunction\" : ['conjunction'],\"determiner\":[\"determiner\"],\"auxilary\" : [\"do\"],\"domain_noun\":['domainnoun'],\"noun\" : [\"noun\"],\"pronoun\":[\"possessive\",\"pronoun\",\"pronun\",\"prounoun\"],\"preposition\":[\"preposition\",\"prepositions\",\"prepositon\",\"prepostion\"],\"wquestion\":[\"question\",\"w question\",\"whquestion\",\"wquestion\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'Which class does your child study in?',\n",
       " 'tokens': ['Which', 'class', 'does', 'your', 'child', 'study', 'in'],\n",
       " 'tags': ['w question',\n",
       "  'ccontextnoun',\n",
       "  'do',\n",
       "  'possessive',\n",
       "  'personentitynouns',\n",
       "  'verb',\n",
       "  'preposition']}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for item in data:\n",
    "    for tag in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
