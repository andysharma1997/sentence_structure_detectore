{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_df = pd.read_pickle(\"/home/andy/Desktop/sken_project/sentence_structure_detectore/src/resources/sequence.pkl\")\n",
    "tags_df = pd.read_pickle(\"/home/andy/Desktop/sken_project/sentence_structure_detectore/src/resources/encoder1.pkl\")\n",
    "new_seq_df = pd.read_excel('/home/andy/Downloads/Razor Model Testing Data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_seq_sentences=sequence_df.sentence.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_sen = new_seq_df[\"Root Sentence\"].to_list()\n",
    "cols=[]\n",
    "for i in range(10):\n",
    "    cols.append(\"Variation {}\".format(i+1))\n",
    "for i,val in new_seq_df[cols].iterrows():\n",
    "    if type(val[0]) is not float:\n",
    "        meta_sen.append(val[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_clean_text(sentence):\n",
    "    return re.sub(r'[^a-zA-Z ]+', '', sentence).lower()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_noun = tags_df[\"context_noun\"].to_list()\n",
    "new_nouns=[]\n",
    "for noun in context_noun:\n",
    "    if noun is not None:\n",
    "        new_nouns.append(noun)\n",
    "context_noun=new_nouns\n",
    "\n",
    "question = tags_df[\"wquestions\"].to_list()\n",
    "new_question=[]\n",
    "for ques in question:\n",
    "    if ques is not None:\n",
    "        new_question.append(ques)\n",
    "question=new_question\n",
    "\n",
    "contex_verb = tags_df[\"context_verb\"].to_list()\n",
    "new_verb=[]\n",
    "for verb in contex_verb:\n",
    "    if verb is not None:\n",
    "        new_verb.append(verb)\n",
    "contex_verb=new_verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "567 526 7 111\n"
     ]
    }
   ],
   "source": [
    "print(len(context_noun),len(contex_verb),len(question),len(sequence_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = []\n",
    "for sen in meta_sen:\n",
    "    if type(sen) is not float:\n",
    "        clean_text =return_clean_text(sen)\n",
    "        resp = {\"sentence\": clean_text, \"sequence\": ''}\n",
    "        if clean_text not in sequence_df.sentence.to_list():\n",
    "            doc = nlp(sen)\n",
    "            for token in doc:\n",
    "                if 'W' in token.tag_:\n",
    "                    if str(token) in question:\n",
    "                        resp['sequence'] += \"<wquestion>\"\n",
    "                    else:\n",
    "                        question.append(str(token))\n",
    "                        resp['sequence'] += \"<wquestion>\"\n",
    "                elif 'VERB' in token.pos_:\n",
    "                    if str(token) in contex_verb:\n",
    "                        resp[\"sequence\"] += '<context_verb>'\n",
    "\n",
    "                    else:\n",
    "                        contex_verb.append(str(token))\n",
    "                        resp[\"sequence\"] += '<context_verb>'\n",
    "                elif 'NOUN' in token.pos_:\n",
    "                    if str(token) in context_noun:\n",
    "                        resp['sequence'] += \"<context_noun>\"        \n",
    "                    else:\n",
    "                        context_noun.append(str(token))\n",
    "                        resp['sequence'] += \"<context_noun>\"\n",
    "                else:\n",
    "                    resp['sequence'] += '<' + str(spacy.explain(token.pos_)) + '>'\n",
    "            new_data.append(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = sequence_df.append(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_pickle(\"/home/andy/Desktop/sken_project/sentence_structure_detectore/src/resources/sequence1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "enocder_df = pd.DataFrame.from_dict({\"context_noun\":list(set(context_noun)),\"context_verb\":list(set(contex_verb)),\"wquestions\":list(set(question))},orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=enocder_df.transpose()\n",
    "x.to_pickle(\"/home/andy/Desktop/sken_project/sentence_structure_detectore/src/resources/encoder2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
